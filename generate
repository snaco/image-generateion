#!/usr/bin/env python3

from datetime import datetime
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, DiffusionPipeline
from time import sleep
import os
import re
import subprocess
import sys
import torch
from upscale import upscale, models
import gc

from PIL import ImageFilter
from PIL import Image

launch_time = datetime.now().strftime('%H:%M:%S')
launch_date = datetime.now().strftime('%Y-%m-%d')
nvidia_temp_command = 'nvidia-smi -q -d temperature'
gpu_temp_regex = re.compile('GPUCurrentTemp')
args = sys.argv
torch.cuda.empty_cache()
gc.collect()

def argsHasFlag(args, flag):
  return len(list(filter(lambda x: flag in x, args))) > 0

def get_temp() -> int:
  with (subprocess.Popen(nvidia_temp_command.split(), stdout=subprocess.PIPE)) as process:
    output, error = process.communicate()
    lines = str(output).split('\\n')
    lines = list(map(lambda x: x.replace(' ', ''), lines))
    return int(list(filter(gpu_temp_regex.match, lines))[0].split(':')[1][:-1])

height=None
if (argsHasFlag(args, '--height')):
  arg_index = args.index('--height')
  height = int(args.pop(arg_index+1))
  args.pop(arg_index)

width=None
if (argsHasFlag(args, '--width')):
  arg_index = args.index('--width')
  width = int(args.pop(arg_index+1))
  args.pop(arg_index)

memory_efficient=False
if (argsHasFlag(args, '--memory-efficient')):
  arg_index = args.index('--memory-efficient')
  memory_efficient = True
  args.pop(arg_index)

count=1
if argsHasFlag(args, '--count'):
  arg_index = args.index('--count')
  count = int(args.pop(arg_index+1))
  args.pop(arg_index)

base_output_path='./output'
if (argsHasFlag(args, '--output-dir')):
  arg_index = args.index('--output-dir')
  base_output_path=args.pop(arg_index+1)
  if base_output_path.endswith('/'):
    base_output_path = base_output_path[:-1]
  args.pop(arg_index)

wide=False
wide_scale=1
if (argsHasFlag(args, '--wide')):
  arg_index = args.index('--wide')
  wide_scale = int(args.pop(arg_index+1))
  args.pop(arg_index)
  wide = True

tall=False
tall_scale=1
if (argsHasFlag(args, '--tall')):
  arg_index = args.index('--tall')
  tall_scale = int(args.pop(arg_index+1))
  args.pop(arg_index)
  tall = True

do_upscale=False
upscale_passes = 1
if (argsHasFlag(args, '--upscale')):
  arg_index = args.index('--upscale')
  upscale_passes = int(args.pop(arg_index+1))
  args.pop(arg_index)
  do_upscale=True

do_cooldown = True
if (argsHasFlag(args, '--no-cooldown')):
  args.remove('--no-cooldown')
  do_cooldown = False

diffuser_names = {
  'protogen': 'darkstorm2150/Protogen_Infinity_Official_Release',
  'dream2': 'dreamlike-art/dreamlike-photoreal-2.0',
  'epic': 'johnslegers/epic-diffusion-v1.1',
  'dream1': 'dreamlike-art/dreamlike-diffusion-1.0',
  'er': 'nitrosocke/elden-ring-diffusion',
  'lowpoly': 'MirageML/lowpoly-world',
  "sci-fi": 'Joeythemonster/sci-fi-landscape',
  'nitro': 'nitrosocke/Nitro-Diffusion',
  'sd2': 'stabilityai/stable-diffusion-2-1'
}

def get_diffuser_name(diffuser_key: str):
  if diffuser_key in diffuser_names:
    return diffuser_names[diffuser_key]
  return diffuser_names['protogen']

def get_pipe(diffuser_key: str):
  if diffuser_key in diffuser_names.keys():
    return DiffusionPipeline.from_pretrained(diffuser_names[diffuser_key], torch_dtype=torch.float16)
  return DiffusionPipeline.from_pretrained(diffuser_names['protogen'], torch_dtype=torch.float16)

diffuser_keys = []
do_diffuser_flight = False
if (argsHasFlag(args, '--diffuser-flight')):
  do_diffuser_flight = True
  args.remove('--diffuser-flight')
  diffuser_keys = []
  for key in diffuser_names:
    diffuser_keys.append(key)


if (argsHasFlag(args, '--diffuser')):
  diffuser_index = args.index('--diffuser')
  diffuser_key = args.pop(diffuser_index+1).lower()
  args.pop(diffuser_index)
  diffuser_keys = [diffuser_key]


prompts = args[1:]

for diffuser_key in diffuser_keys:
  torch.cuda.empty_cache()
  gc.collect()
  diffuser = get_diffuser_name(diffuser_key)
  print(f'using {diffuser}')
  pipe = get_pipe(diffuser_key)
  pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
  if memory_efficient:
    pipe.enable_attention_slicing()
    pipe.enable_xformers_memory_efficient_attention()
  pipe = pipe.to('cuda')
  dir_index = 1
  for prompt in prompts:
    path_index = f'/{dir_index}' if len(prompts) > 1 else ''
    diffuser_path = f'/{diffuser_key}' if do_diffuser_flight else ''
    base_path = f'{base_output_path}/{launch_date}/{launch_time}{diffuser_path}{path_index}'
    prompt_file = f'{base_path}/prompt.txt'
    os.makedirs(os.path.dirname(prompt_file), exist_ok=True)
    with open(f'{prompt_file}', 'w') as f:
        f.write(prompt)
    for index in range(1, count+1):
      if do_cooldown:
        nvidia_temp = get_temp()
        print(f'GPU Temp: {nvidia_temp}ºC')
        if (nvidia_temp > 75):
          print('Pausing to cool down.')
          while (nvidia_temp > 70):
            time = datetime.now().strftime('%H:%M:%S')
            sleep(5)
            nvidia_temp = get_temp()
            print(f'[{time}] Temp: {nvidia_temp}ºC')
          print(f'Temp: {nvidia_temp}ºC')
          print('Resuming.')
      if (not width and not height and wide):
        height=int(9*8*wide_scale)
        width=int(16*8*wide_scale)
        print(f'using wide aspect ratio, {width}x{height}')
      if (not width and not height and tall):
        height=int(16*8*tall_scale)
        width=int(9*8*tall_scale)
        print(f'using tall aspect ratio, {width}x{height}')
      # generate image
      print(f'generating: {prompt}')
      # generator = [torch.Generator(device="cuda").manual_seed(0) for i in range(4)]
      # generator = torch.Generator(device="cuda").manual_seed(index)
      image = pipe(prompt, height=height, width=width).images[0] # num_inference_steps=1
      file_name = f'{base_path}/{index}.png'
      os.makedirs(os.path.dirname(f'{file_name}'), exist_ok=True)
      if (do_upscale):
        print('upscaling image...')
        for _pass in range(0, upscale_passes):
          image = upscale(image, models['2x'])
        print(f'saving image {image.width}x{image.height}')
      image.save(f'{file_name}')
        
    dir_index = dir_index + 1
